{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4467c03",
   "metadata": {},
   "source": [
    "# Dataloader Sanity Check for `fed_Cifar10.py`\n",
    "\n",
    "This notebook is designed to test and visualize the data loaders created by the `get_dataloaders` function in `fed_Cifar10.py`. We will:\n",
    "1.  **Define the Dataloader Logic**: Replicate the `SimpleNPZDataset` class and `get_dataloaders` function.\n",
    "2.  **Create Mock Data**: Generate dummy `.npz` files to simulate the expected data structure.\n",
    "3.  **Load Dataloaders**: Instantiate all the different data loaders.\n",
    "4.  **Visualize Batches**: Define a helper function to display images and their labels from a batch.\n",
    "5.  **Inspect Each Loader**: Run visualization for each data loader to ensure they are loading the correct data as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73200c2",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Define Necessary Classes/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d58a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Copy the classes and functions from the script\n",
    "class SimpleNPZDataset(Dataset):\n",
    "    def __init__(self, npz_path):\n",
    "        self.mean = 0.5\n",
    "        self.std = 0.5\n",
    "        with open(npz_path, 'rb') as f:\n",
    "            data = np.load(f, allow_pickle=True)['data'].tolist()\n",
    "        \n",
    "        # The data is a list with a single dictionary element\n",
    "        data_dict = data[0]\n",
    "        self.images = data_dict['x']\n",
    "        self.labels = data_dict['y']\n",
    "        \n",
    "        mask_open = self.labels >= 6\n",
    "        if np.any(mask_open):\n",
    "            self.labels[mask_open] = 6\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = (img - self.mean) / self.std\n",
    "        img = torch.tensor(img)\n",
    "        return img, int(label)\n",
    "\n",
    "def get_dataloaders(data_root, batchsize=10, num_workers=1):\n",
    "    # This function is copied directly from your script\n",
    "    trainloaders = []\n",
    "    for i in range(5):\n",
    "        npz_path = f\"{data_root}/train/{i}.npz\"\n",
    "        ds = SimpleNPZDataset(npz_path)\n",
    "        trainloaders.append(DataLoader(ds, batch_size=batchsize, shuffle=True, num_workers=num_workers))\n",
    "        \n",
    "    close_test_path = f\"{data_root}/centralized_close_test.npz\"\n",
    "    close_ds = SimpleNPZDataset(close_test_path)\n",
    "    valloader = DataLoader(close_ds, batch_size=batchsize, shuffle=False, num_workers=num_workers)\n",
    "    closerloader = DataLoader(close_ds, batch_size=batchsize, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    open_test_path = f\"{data_root}/centralized_open_test.npz\"\n",
    "    open_ds = SimpleNPZDataset(open_test_path)\n",
    "    openloader = DataLoader(open_ds, batch_size=batchsize, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    train_val_loaders = []\n",
    "    for i in range(5):\n",
    "        npz_path = f\"{data_root}/test/{i}.npz\"\n",
    "        ds = SimpleNPZDataset(npz_path)\n",
    "        train_val_loaders.append(DataLoader(ds, batch_size=batchsize, shuffle=False, num_workers=num_workers))\n",
    "    \n",
    "    print(\"--- Dataloader Batch Shapes Check ---\")\n",
    "    # ... (the print checks are omitted for brevity in the notebook but will run)\n",
    "    \n",
    "    return trainloaders, valloader, closerloader, openloader, train_val_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a66251",
   "metadata": {},
   "source": [
    "### 2. Create Mock Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7d6032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy data created in 'dummy_cifar_data' directory.\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy directory structure and .npz files\n",
    "DATA_ROOT = \"dummy_cifar_data\"\n",
    "os.makedirs(os.path.join(DATA_ROOT, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(DATA_ROOT, \"test\"), exist_ok=True)\n",
    "\n",
    "def create_dummy_npz(path, num_samples, label_gen_fn):\n",
    "    \"\"\"Creates a dummy NPZ file with random images and specific labels.\"\"\"\n",
    "    images = np.random.randint(0, 256, size=(num_samples, 32, 32, 3), dtype=np.uint8)\n",
    "    labels = label_gen_fn(num_samples)\n",
    "    np.savez_compressed(path, data=np.array([{'x': images, 'y': labels}], dtype=object))\n",
    "\n",
    "# Create train files (0.npz to 4.npz)\n",
    "for i in range(5):\n",
    "    create_dummy_npz(\n",
    "        os.path.join(DATA_ROOT, \"train\", f\"{i}.npz\"),\n",
    "        num_samples=20,\n",
    "        label_gen_fn=lambda n: np.random.randint(0, 6, size=n) # Known classes\n",
    "    )\n",
    "\n",
    "# Create test files (0.npz to 4.npz)\n",
    "for i in range(5):\n",
    "    create_dummy_npz(\n",
    "        os.path.join(DATA_ROOT, \"test\", f\"{i}.npz\"),\n",
    "        num_samples=15,\n",
    "        label_gen_fn=lambda n: np.random.randint(0, 6, size=n) # Known classes\n",
    "    )\n",
    "\n",
    "# Create centralized test files\n",
    "create_dummy_npz(\n",
    "    os.path.join(DATA_ROOT, \"centralized_close_test.npz\"),\n",
    "    num_samples=50,\n",
    "    label_gen_fn=lambda n: np.random.randint(0, 6, size=n) # Known classes\n",
    ")\n",
    "create_dummy_npz(\n",
    "    os.path.join(DATA_ROOT, \"centralized_open_test.npz\"),\n",
    "    num_samples=30,\n",
    "    label_gen_fn=lambda n: np.random.randint(6, 10, size=n) # Open-set classes\n",
    ")\n",
    "\n",
    "print(f\"Dummy data created in '{DATA_ROOT}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29bb344",
   "metadata": {},
   "source": [
    "### 3. Load the Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198c7cad",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load all the dataloaders using the dummy data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m trainloaders, valloader, closerloader, openloader, train_val_loaders = \u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATA_ROOT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mget_dataloaders\u001b[39m\u001b[34m(data_root, batchsize, num_workers)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m     35\u001b[39m     npz_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/train/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     ds = \u001b[43mSimpleNPZDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpz_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     trainloaders.append(DataLoader(ds, batch_size=batchsize, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers=num_workers))\n\u001b[32m     39\u001b[39m close_test_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/centralized_close_test.npz\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mSimpleNPZDataset.__init__\u001b[39m\u001b[34m(self, npz_path)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(npz_path, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     13\u001b[39m     data = np.load(f, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m].tolist()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mself\u001b[39m.images = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mself\u001b[39m.labels = data[\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     16\u001b[39m mask_open = \u001b[38;5;28mself\u001b[39m.labels >= \u001b[32m6\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Load all the dataloaders using the dummy data\n",
    "trainloaders, valloader, closerloader, openloader, train_val_loaders = get_dataloaders(\n",
    "    data_root=DATA_ROOT,\n",
    "    batchsize=8,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a29f5",
   "metadata": {},
   "source": [
    "### 4. Define Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ee81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_batch(dataloader, title):\n",
    "    \"\"\"Fetches a batch from the dataloader and displays the images and labels.\"\"\"\n",
    "    try:\n",
    "        inputs, labels = next(iter(dataloader))\n",
    "        \n",
    "        # Denormalize the images\n",
    "        inputs = inputs * 0.5 + 0.5  # Reverse the normalization (std*img + mean)\n",
    "        inputs = np.clip(inputs, 0, 1)\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "        for i in range(inputs.shape[0]):\n",
    "            ax = plt.subplot(2, 4, i + 1) # Display up to 8 images\n",
    "            # The images are HWC, which is what imshow expects\n",
    "            plt.imshow(inputs[i])\n",
    "            ax.set_title(f\"Label: {labels[i].item()}\")\n",
    "            ax.axis('off')\n",
    "            if i == 7: break # Stop after 8 images\n",
    "        plt.show()\n",
    "    except StopIteration:\n",
    "        print(f\"Dataloader '{title}' is empty.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while visualizing '{title}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b61be",
   "metadata": {},
   "source": [
    "### 5. Visualize `trainloaders` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first client's training data\n",
    "imshow_batch(trainloaders[0], \"Trainloader[0] - Client 1 Training Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8acbc25",
   "metadata": {},
   "source": [
    "### 6. Visualize `valloader` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the centralized validation data\n",
    "imshow_batch(valloader, \"Valloader - Centralized Close Test Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c319055",
   "metadata": {},
   "source": [
    "### 7. Visualize `closerloader` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the known-class test data\n",
    "imshow_batch(closerloader, \"Closerloader - Centralized Close Test Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c4fb5",
   "metadata": {},
   "source": [
    "### 8. Visualize `openloader` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the open-set test data\n",
    "# We expect all labels to be 6\n",
    "imshow_batch(openloader, \"Openloader - Centralized Open Test Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0b5c9",
   "metadata": {},
   "source": [
    "### 9. Visualize `train_val_loaders` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa80096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first client's test data\n",
    "imshow_batch(train_val_loaders[0], \"Train_Val_Loader[0] - Client 1 Test Data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
